{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKdMLswAXHGRPC8ay424Vf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noakishere/cart498-genai/blob/main/A2/CART498_GENAI_A02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S61CaCju7Gez",
        "outputId": "2d6e12db-2c3e-44e1-d9d6-fefc99d6cdf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "One must have a mind of it\n",
            "To regard the frost and the lack\n",
            "Of the pine-trees crusted with dust\n",
            "And have been cold a long time so\n",
            "To behold the junipers shagged with silver\n",
            "The spruces rough in the distant corners\n",
            "Of the January sun; and not to make\n",
            "Of any misery in the sound of the door\n",
            "In the sound of a few taps\n",
            "Which is the sound of the man\n",
            "Full of the same Ċ\n",
            "That is blowing in the same bare face\n",
            "For the listener, who listens in the form\n",
            "And, nothing himself, however\n",
            "Nothing that is not there and the nothing that doesn\n"
          ]
        }
      ],
      "source": [
        "# Install the transformers library if not already installed\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessorList, TopKLogitsWarper\n",
        "import torch\n",
        "\n",
        "# Initialize the GPT-2 tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "top_k = 20\n",
        "chosenKIndex = 15 # p + x\n",
        "\n",
        "# Define the prompt\n",
        "lines = [\"One must have a mind of\",\n",
        "         \"To regard the frost and the\",\n",
        "         \"Of the pine-trees crusted with\",\n",
        "         \"And have been cold a long time\",\n",
        "         \"To behold the junipers shagged with\",\n",
        "         \"The spruces rough in the distant\",\n",
        "         \"Of the January sun; and not to\",\n",
        "         \"Of any misery in the sound of the\",\n",
        "         \"In the sound of a few\",\n",
        "         \"Which is the sound of the\",\n",
        "         \"Full of the same\",\n",
        "         \"That is blowing in the same bare\",\n",
        "         \"For the listener, who listens in the\",\n",
        "         \"And, nothing himself,\",\n",
        "         \"Nothing that is not there and the nothing that\"]\n",
        "\n",
        "for line in lines:\n",
        "  prompt = line\n",
        "\n",
        "  # Tokenize the prompt and convert it to input IDs\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "  # Generate the model's output logits for the next token\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids)\n",
        "      logits = outputs.logits[:, -1, :]  # Get logits for the last token\n",
        "\n",
        "  # Apply a Top-K logits processor to focus on the most probable continuations\n",
        "  logits_processor = LogitsProcessorList([TopKLogitsWarper(top_k=50)])\n",
        "  processed_logits = logits_processor(input_ids, logits)\n",
        "\n",
        "  # Convert logits to probabilities using softmax\n",
        "  probabilities = torch.softmax(processed_logits, dim=-1).squeeze()\n",
        "\n",
        "  top_probs, top_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "  # Decode the tokens and pair them with their probabilities\n",
        "  continuations = [token.replace(\"Ġ\", \"\") for token in tokenizer.convert_ids_to_tokens(top_indices.tolist())]\n",
        "  results = list(zip(continuations, top_probs.tolist()))\n",
        "\n",
        "  # Display the results\n",
        "  for i, (word, prob) in enumerate(results, 1):\n",
        "      if(i == chosenKIndex):\n",
        "        print(f\"{line} {word}\")\n"
      ]
    }
  ]
}