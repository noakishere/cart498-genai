{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7zzTtK32ehixBTQBMgZT+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noakishere/cart498-genai/blob/main/A2/CART498_GENAI_A02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following algorithm uses **GPT2** to generate text predictability.\n",
        "\n",
        "This predictability is used to create newer poems based on word replacement with X highest ranked predictability.\n",
        "\n",
        "**Original Poem:**\n",
        "The Snow Man\n",
        "by Wallace Stevens (1879-1955)\n",
        "\n",
        "One must have a mind of winter\n",
        "\n",
        "To regard the frost and the boughs\n",
        "\n",
        "Of the pine-trees crusted with snow;\n",
        "\n",
        "And have been cold a long time\n",
        "\n",
        "To behold the junipers shagged with ice,\n",
        "\n",
        "The spruces rough in the distant glitter\n",
        "\n",
        "Of the January sun; and not to think\n",
        "\n",
        "Of any misery in the sound of the wind,\n",
        "\n",
        "In the sound of a few leaves,\n",
        "\n",
        "Which is the sound of the land\n",
        "\n",
        "Full of the same wind\n",
        "\n",
        "That is blowing in the same bare place\n",
        "\n",
        "For the listener, who listens in the snow,\n",
        "\n",
        "And, nothing himself, beholds\n",
        "\n",
        "Nothing that is not there and the nothing that is."
      ],
      "metadata": {
        "id": "YWnfKh1i28Ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S61CaCju7Gez",
        "outputId": "67eb818f-1f8d-4488-d65d-44e1dbd7c35d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "One must have a mind of your\n",
            "To regard the frost and the ice\n",
            "Of the pine-trees crusted with salt\n",
            "And have been cold a long time now\n",
            "To behold the junipers shagged with blood\n",
            "The spruces rough in the distant ,\n",
            "Of the January sun; and not to say\n",
            "Of any misery in the sound of the world\n",
            "In the sound of a few gunshots\n",
            "Which is the sound of the engine\n",
            "Full of the same name\n",
            "That is blowing in the same bare chest\n",
            "For the listener, who listens in the first\n",
            "And, nothing himself, no\n",
            "Nothing that is not there and the nothing that was\n"
          ]
        }
      ],
      "source": [
        "# Install the transformers library if not already installed\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessorList, TopKLogitsWarper\n",
        "import torch\n",
        "\n",
        "# Initialize the GPT-2 tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "top_k = 20\n",
        "chosenKIndex = 4 # p + x\n",
        "\n",
        "# Define the prompt\n",
        "lines = [\"One must have a mind of\",\n",
        "         \"To regard the frost and the\",\n",
        "         \"Of the pine-trees crusted with\",\n",
        "         \"And have been cold a long time\",\n",
        "         \"To behold the junipers shagged with\",\n",
        "         \"The spruces rough in the distant\",\n",
        "         \"Of the January sun; and not to\",\n",
        "         \"Of any misery in the sound of the\",\n",
        "         \"In the sound of a few\",\n",
        "         \"Which is the sound of the\",\n",
        "         \"Full of the same\",\n",
        "         \"That is blowing in the same bare\",\n",
        "         \"For the listener, who listens in the\",\n",
        "         \"And, nothing himself,\",\n",
        "         \"Nothing that is not there and the nothing that\"]\n",
        "\n",
        "for line in lines:\n",
        "  prompt = line\n",
        "\n",
        "  # Tokenize the prompt and convert it to input IDs\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "  # Generate the model's output logits for the next token\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids)\n",
        "      logits = outputs.logits[:, -1, :]  # Get logits for the last token\n",
        "\n",
        "  # Apply a Top-K logits processor to focus on the most probable continuations\n",
        "  logits_processor = LogitsProcessorList([TopKLogitsWarper(top_k=50)])\n",
        "  processed_logits = logits_processor(input_ids, logits)\n",
        "\n",
        "  # Convert logits to probabilities using softmax\n",
        "  probabilities = torch.softmax(processed_logits, dim=-1).squeeze()\n",
        "\n",
        "  top_probs, top_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "  # Decode the tokens and pair them with their probabilities\n",
        "  continuations = [token.replace(\"Ä \", \"\") for token in tokenizer.convert_ids_to_tokens(top_indices.tolist())]\n",
        "  results = list(zip(continuations, top_probs.tolist()))\n",
        "\n",
        "  # Display the results\n",
        "  for i, (word, prob) in enumerate(results, 1):\n",
        "      if(i == chosenKIndex):\n",
        "        print(f\"{line} {word}\")\n"
      ]
    }
  ]
}